{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import re\n",
    "\n",
    "from einops import pack, unpack\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "from transformers import HubertModel\n",
    "from customtokenizer import CustomTokenizer\n",
    "\n",
    "from bark_conference import *\n",
    "from Langchain_conference import *\n",
    "from matching import *\n",
    "import custom_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 변수 선언\n",
    "\n",
    "narrator_path = None\n",
    "narrator_type = None\n",
    "custom_path = None\n",
    "langchain_result = None\n",
    "voices = None\n",
    "button_if = False\n",
    "scenario = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npz 생성 관련 model load\n",
    "def load_model(narr=True):\n",
    "    device='cuda'\n",
    "\n",
    "    print('Loading HuBERT...')\n",
    "    hubert_model = HubertModel.from_pretrained(\"team-lucid/hubert-base-korean\")\n",
    "    hubert_model.to(device)\n",
    "\n",
    "    print('Loading Quantizer...')\n",
    "    if narr: \n",
    "        quant_model = CustomTokenizer.load_from_checkpoint(\"../KOR-HuBERT-Quantizer/Literature/new_model_epoch_37.pth\", device)\n",
    "    else:\n",
    "        quant_model = CustomTokenizer.load_from_checkpoint(\"../KOR-HuBERT-Quantizer/Literature/new_model_epoch_8.pth\", device)\n",
    "        \n",
    "\n",
    "    print('Loading Encodec...')\n",
    "    encodec_model = EncodecModel.encodec_model_24khz()\n",
    "    encodec_model.set_target_bandwidth(6.0)\n",
    "    encodec_model.to(device)\n",
    "\n",
    "    print('Downloaded and loaded models!')\n",
    "    return hubert_model, quant_model, encodec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 실행\n",
    "def process_text(novel_text):\n",
    "    global langchain_result\n",
    "    langchain_result = langchain(novel_text)\n",
    "    # 결과를 문자열로 포맷팅\n",
    "    characters_str = \", \".join([f\"{name}:{attributes}\" for name, attributes in langchain_result['Characters'].items()])\n",
    "    scenario_str = \"\\n\".join([f\"{item[0]}: '{item[1]}', {item[2]}\" if len(item) == 3 else f\"{item[0]}: '{item[1]}'\" for item in langchain_result['Scenario']])\n",
    "\n",
    "    formatted_result = f\"Characters:\\n{characters_str}\\n\\nScenario:\\n{scenario_str}\"\n",
    "    return formatted_result\n",
    "\n",
    "novel_text = \"여기에 소설 텍스트를 입력합니다.\"\n",
    "\n",
    "# Langchain 결과 처리 및 출력\n",
    "langchain_result = process_text(novel_text)\n",
    "print(langchain_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 업로드 후 처리를 위한 함수 정의\n",
    "def process_uploaded_file(change):\n",
    "    upload = change.owner\n",
    "    if upload.data:\n",
    "        uploaded_filename = next(iter(upload.value))  # 업로드된 파일 이름 가져오기\n",
    "        content = upload.data[0]  # 업로드된 파일의 내용\n",
    "\n",
    "        # 저장할 경로 설정\n",
    "        save_directory = '../demo/voice/custom/'\n",
    "        save_path = os.path.join(save_directory, 'uploaded_voice.wav')\n",
    "\n",
    "        # 파일 저장\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "\n",
    "        # 모델 로딩 및 음성 처리 (가정)\n",
    "        hubert_model, quant_model, encodec_model = load_model()\n",
    "        global custom_path\n",
    "        custom_path = create_voice(save_path, hubert_model, quant_model, encodec_model)\n",
    "        \n",
    "        # 처리 완료 메시지 표시\n",
    "        clear_output()\n",
    "        print(f'파일이 처리되었습니다: {custom_path}')\n",
    "    else:\n",
    "        clear_output()\n",
    "        print(\"파일이 업로드되지 않았습니다.\")\n",
    "\n",
    "upload = FileUpload(accept='.wav', multiple=False)\n",
    "upload.observe(process_uploaded_file, names='data')\n",
    "\n",
    "# 위젯 표시\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내레이터 선택 및 로드 처리 함수\n",
    "def process_narrative_selection(gender, age):\n",
    "    global narrator_type\n",
    "    \n",
    "    filename = f\"{gender}_{age}.npz\" \n",
    "    file_path = f\"../demo/voice/narrator/{filename}\"\n",
    "    \n",
    "    try:\n",
    "        # npz 파일 로드\n",
    "        data = np.load(file_path)\n",
    "        # 로드된 데이터를 전역 변수에 저장\n",
    "        narrator_type = data\n",
    "        print(f\"'{filename}' 파일이 성공적으로 로드되었습니다.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"'{file_path}' 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "# 둘 중에 하나를 골라서 사용하세요\n",
    "process_narrative_selection('남', '성인')  # '여', '성인'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_algorithm():\n",
    "    global narrator_type\n",
    "    global narrator_path\n",
    "    global custom_path\n",
    "    global langchain_result\n",
    "    global scenario\n",
    "    global voices\n",
    "\n",
    "    # 나레이터 경로 설정\n",
    "    if custom_path:\n",
    "        narrator_path = custom_path\n",
    "    else:\n",
    "        narrator_path = matching.preset_narr(narrator_type[0], narrator_type[1], False)\n",
    "\n",
    "    # langchain 결과에서 캐릭터 정보와 시나리오 추출\n",
    "    characters = langchain_result['Characters']\n",
    "    scenario = langchain_result['Scenario']\n",
    "\n",
    "    # 캐릭터별 목소리 매칭\n",
    "    voices = matching.match_character(characters)\n",
    "    voices['Narrator'] = narrator_path\n",
    "\n",
    "    # 매칭 결과 출력\n",
    "    print(\"매칭된 목소리 파일 경로:\")\n",
    "    for character, voice_path in voices.items():\n",
    "        print(f\"{character}: {voice_path}\")\n",
    "\n",
    "# matching_algorithm 함수 실행\n",
    "matching_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오디오 생성 및 결합\n",
    "def full_bark_wrapper():\n",
    "    matching_algorithm()\n",
    "\n",
    "    if scenario is None or voices is None:\n",
    "        print(\"scenario 또는 voices가 설정되지 않았습니다.\")\n",
    "        return {\"audios\": []}\n",
    "\n",
    "    full_bark(scenario, voices)\n",
    "    audio_book = combine('../demo/voice/audio_book/result')\n",
    "\n",
    "full_bark_wrapper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
